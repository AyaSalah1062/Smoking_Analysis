{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cU6yF_DVQXlX"
      },
      "source": [
        "# Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "0v3PNgUpQlBO"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer as ColumnTransformer_old\n",
        "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer\n",
        "from scipy.stats import skew\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3bQnKACRtKi"
      },
      "source": [
        "# Generate dataset using the given script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "rKFGR6VkRu7T"
      },
      "outputs": [],
      "source": [
        "id_1 = 7361\n",
        "id_2 = 7371\n",
        "id_3 = 7501\n",
        "random_seed = id_1 + id_2 + id_3\n",
        "random.seed(random_seed)\n",
        "\n",
        "# Script to generate dataset variant\n",
        "data_path = \"Data.csv\"\n",
        "output_path = \"your_data.csv\"\n",
        "\n",
        "all_data = pd.read_csv(data_path, index_col=0)\n",
        "all_columns = all_data.columns.tolist()\n",
        "\n",
        "target_column = 'smoking'\n",
        "\n",
        "selected_columns = random.sample(all_columns, 10)\n",
        "selected_columns = np.append(selected_columns, target_column)\n",
        "sample_df = all_data[selected_columns].copy()\n",
        "sample_df.to_csv(output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzb7JGO1R0PB"
      },
      "source": [
        "# Load and split the generated dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdpw8OJMSd2N",
        "outputId": "78b3f295-7915-4a2e-819c-fc33518d3eed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set shape: (111479, 10)\n",
            "Validation set shape: (23888, 10)\n",
            "Test set shape: (23889, 10)\n",
            "Columns: ['dental caries' 'Cholesterol' 'eyesight(right)' 'systolic' 'age'\n",
            " 'Urine protein' 'hearing(right)' 'eyesight(left)' 'height(cm)' 'Gtp'\n",
            " 'smoking']\n"
          ]
        }
      ],
      "source": [
        "data_path = 'your_data.csv'\n",
        "df = pd.read_csv(data_path, index_col=0)\n",
        "df = df.dropna(subset=['smoking'])\n",
        "\n",
        "# Set the target column\n",
        "target_column = 'smoking'\n",
        "\n",
        "# Split the data into training, validation, and test sets\n",
        "X = df.drop(target_column, axis=1)\n",
        "y = df[target_column]\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# # Save the split datasets to separate CSV files\n",
        "# train_path = 'train_data.csv'\n",
        "# valid_path = 'valid_data.csv'\n",
        "# test_path = 'test_data.csv'\n",
        "\n",
        "y_train = y.loc[X_train.index]\n",
        "y_valid = y.loc[X_valid.index]\n",
        "y_test = y.loc[X_test.index]\n",
        "\n",
        "# X_train.to_csv(train_path, index=False)\n",
        "# X_valid.to_csv(valid_path, index=False)\n",
        "# X_test.to_csv(test_path, index=False)\n",
        "\n",
        "# Display the shapes of the split datasets\n",
        "print(\"Train set shape:\", X_train.shape)\n",
        "print(\"Validation set shape:\", X_valid.shape)\n",
        "print(\"Test set shape:\", X_test.shape)\n",
        "print(\"Columns:\" ,selected_columns)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature engineering:"
      ],
      "metadata": {
        "id": "fN2Xmto9ES6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy before feature engineering\n",
        "model_before = RandomForestClassifier(random_state=42)\n",
        "model_before.fit(X_train, y_train)\n",
        "y_pred_before = model_before.predict(X_valid)\n",
        "accuracy_before = accuracy_score(y_valid, y_pred_before)\n",
        "print(f'Accuracy before feature engineering: {accuracy_before}')\n",
        "\n",
        "# Feature Engineering (including handling outliers)\n",
        "# Function to calculate skewness of numerical features\n",
        "def calculate_skewness(df):\n",
        "    skewness = df.apply(lambda x: skew(x))\n",
        "    skewness = skewness[abs(skewness) > 0.5]\n",
        "    return skewness.index\n",
        "\n",
        "# Function for log transformation of skewed features\n",
        "def log_transform_skewed_features(df):\n",
        "    skewed_features = calculate_skewness(df)\n",
        "    df[skewed_features] = np.log1p(df[skewed_features])\n",
        "    return df\n",
        "\n",
        "# Custom transformer to select numerical or categorical columns\n",
        "class FeatureSelector:\n",
        "    def __init__(self, feature_names):\n",
        "        self.feature_names = feature_names\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X[self.feature_names]\n",
        "\n",
        "# Custom transformer to handle missing values\n",
        "class MissingValueHandler:\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X.fillna(X.median())  # Replace missing values with median (you can customize this)\n",
        "\n",
        "# Apply feature engineering to training, validation, and test datasets\n",
        "feature_engineering_pipeline = Pipeline([\n",
        "    ('features', FeatureSelector(X_train.columns)),\n",
        "    ('log_transform', FunctionTransformer(log_transform_skewed_features)),\n",
        "    ('impute', SimpleImputer(strategy='median')),  # Impute missing values\n",
        "    ('scaler', RobustScaler())  # Use RobustScaler for normalization\n",
        "])\n",
        "\n",
        "X_train_processed = feature_engineering_pipeline.fit_transform(X_train)\n",
        "X_valid_processed = feature_engineering_pipeline.transform(X_valid)\n",
        "X_test_processed = feature_engineering_pipeline.transform(X_test)\n",
        "\n",
        "# Accuracy after feature engineering\n",
        "model_after = RandomForestClassifier(random_state=42)\n",
        "model_after.fit(X_train_processed, y_train)\n",
        "y_pred_after = model_after.predict(X_valid_processed)\n",
        "accuracy_after = accuracy_score(y_valid, y_pred_after)\n",
        "print(f'Accuracy after feature engineering: {accuracy_after}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJhKid9YERHZ",
        "outputId": "2cb6434e-dd8d-47e3-de83-a112c65b0c65"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy before feature engineering: 0.735976222371065\n",
            "Accuracy after feature engineering: 0.737399531145345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8vQLd9STK-g"
      },
      "source": [
        "# Bagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "k0l0ttcyTWxo"
      },
      "outputs": [],
      "source": [
        "class BaggingClassifier(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, base_estimator, n_estimators, random_state=None):\n",
        "        self.base_estimator = base_estimator\n",
        "        self.n_estimators = n_estimators\n",
        "        self.random_state = random_state\n",
        "        self.models = []\n",
        "\n",
        "    def fit(self, X, y, max_depth=None):\n",
        "        self.models = []\n",
        "        for i in range(self.n_estimators):\n",
        "            model = self.base_estimator(random_state=self.random_state + i)\n",
        "            self.models.append(model.fit(X, y))\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = [model.predict(X) for model in self.models]\n",
        "        return np.round(np.mean(predictions, axis=0))\n",
        "\n",
        "    def score(self, X, y):\n",
        "        predictions = self.predict(X)\n",
        "        return accuracy_score(y, predictions)\n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "        return {\n",
        "            'base_estimator': self.base_estimator,\n",
        "            'n_estimators': self.n_estimators,\n",
        "            'random_state': self.random_state\n",
        "        }\n",
        "\n",
        "    def set_params(self, **params):\n",
        "        for param, value in params.items():\n",
        "            setattr(self, param, value)\n",
        "        return self"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n0IaTkXTh0j"
      },
      "source": [
        "# Boosting (AdaBoost)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "llLNyiKEIGoO"
      },
      "outputs": [],
      "source": [
        "class AdaBoostClassifier(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, base_estimator, n_estimators, random_state=None):\n",
        "        self.base_estimator = base_estimator\n",
        "        self.n_estimators = n_estimators\n",
        "        self.random_state = random_state\n",
        "        self.models = []\n",
        "        self.alphas = []\n",
        "\n",
        "    def fit(self, X, y, base_estimator_max_depth=None):\n",
        "        m = X.shape[0]\n",
        "        weights = np.ones(m) / m\n",
        "\n",
        "        for i in range(self.n_estimators):\n",
        "            model = self.base_estimator.__class__(max_depth=base_estimator_max_depth, random_state=self.random_state + i)\n",
        "            model.fit(X, y, sample_weight=weights)\n",
        "            predictions = model.predict(X)\n",
        "\n",
        "            error = np.sum(weights * (predictions != y)) / np.sum(weights)\n",
        "            alpha = 0.5 * np.log((1 - error) / error)\n",
        "            weights = weights * np.exp(-alpha * y * predictions)\n",
        "            weights /= np.sum(weights)\n",
        "\n",
        "            self.models.append((model, alpha))\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = [alpha * model.predict(X) for model, alpha in self.models]\n",
        "        return np.round(np.sum(predictions, axis=0) / np.sum([alpha for _, alpha in self.models]))\n",
        "\n",
        "    def score(self, X, y):\n",
        "        predictions = self.predict(X)\n",
        "        return accuracy_score(y, predictions)\n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "        return {\n",
        "            'base_estimator': self.base_estimator,\n",
        "            'n_estimators': self.n_estimators,\n",
        "            'random_state': self.random_state\n",
        "        }\n",
        "\n",
        "    def set_params(self, **params):\n",
        "        for param, value in params.items():\n",
        "            setattr(self, param, value)\n",
        "        return self\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrV0Gh16TqIX"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "gqoIsvf2Tsbf"
      },
      "outputs": [],
      "source": [
        "class RandomForestClassifier(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, n_estimators=100, max_features=None, random_state=None):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_features = max_features\n",
        "        self.random_state = random_state\n",
        "        self.models = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X_array = np.array(X)\n",
        "        if X_array.ndim > 2:\n",
        "            raise ValueError(\"Input data with more than two dimensions is not supported.\")\n",
        "\n",
        "        for i in range(self.n_estimators):\n",
        "            if self.max_features is not None:\n",
        "                selected_features = np.random.choice(X_array.shape[1], self.max_features, replace=True)\n",
        "                X_subset = X_array[:, selected_features]\n",
        "            else:\n",
        "                X_subset = X_array\n",
        "\n",
        "            model = DecisionTreeClassifier(random_state=self.random_state + i)\n",
        "            model.fit(X_subset, y)\n",
        "            self.models.append((model, selected_features if self.max_features is not None else None))\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        X_array = np.array(X)\n",
        "        if X_array.ndim > 2:\n",
        "            raise ValueError(\"Input data with more than two dimensions is not supported.\")\n",
        "\n",
        "        predictions = [model.predict(X_array[:, features]) for model, features in self.models]\n",
        "        return np.round(np.mean(predictions, axis=0))\n",
        "\n",
        "    def score(self, X, y):\n",
        "        predictions = self.predict(X)\n",
        "        return accuracy_score(y, predictions)\n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "        return {\n",
        "            'n_estimators': self.n_estimators,\n",
        "            'max_features': self.max_features,\n",
        "            'random_state': self.random_state\n",
        "        }\n",
        "\n",
        "    def set_params(self, **params):\n",
        "        for param, value in params.items():\n",
        "            setattr(self, param, value)\n",
        "        return self"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ripHev1ULyLa"
      },
      "source": [
        "# HyperParameters Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using GridSearchCV**"
      ],
      "metadata": {
        "id": "8PRfsRGIQDPv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohLdBbVB003U",
        "outputId": "26f415da-7b18-4fa3-9b42-5ca36ba25b5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Bagging Model Accuracy on Validation Set: 0.7458556597454788\n",
            "Best Bagging Model Accuracy on Test Set: 0.7489639583071707\n",
            "Best AdaBoost Model Accuracy on Validation Set: 0.7413764233087743\n",
            "Best AdaBoost Model Accuracy on Test Set: 0.7441918874795931\n",
            "Best Random Forest Model Accuracy on Validation Set: 0.7366041527126591\n",
            "Best Random Forest Model Accuracy on Test Set: 0.7371593620494789\n"
          ]
        }
      ],
      "source": [
        "#Bagging\n",
        "bagging_param_grid = {\n",
        "    'n_estimators': [5, 10, 20],\n",
        "    'base_estimator__max_depth': [None, 5, 10]  # Specify within the base estimator\n",
        "}\n",
        "\n",
        "bagging_base_estimator = DecisionTreeClassifier()\n",
        "bagging_model = BaggingClassifier(base_estimator=bagging_base_estimator, n_estimators=10, random_state=42)\n",
        "\n",
        "bagging_grid_search = GridSearchCV(bagging_model, bagging_param_grid, cv=3, scoring='accuracy')\n",
        "bagging_grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_bagging_model = bagging_grid_search.best_estimator_\n",
        "\n",
        "# Evaluate on the validation set\n",
        "bagging_valid_predictions = best_bagging_model.predict(X_valid)\n",
        "bagging_valid_accuracy = accuracy_score(y_valid, bagging_valid_predictions)\n",
        "print(f'Best Bagging Model Accuracy on Validation Set: {bagging_valid_accuracy}')\n",
        "\n",
        "# Evaluate on the test set\n",
        "bagging_test_predictions = best_bagging_model.predict(X_test)\n",
        "bagging_test_accuracy = accuracy_score(y_test, bagging_test_predictions)\n",
        "print(f'Best Bagging Model Accuracy on Test Set: {bagging_test_accuracy}')\n",
        "# print(f'Best Bagging Model Hyperparameters: {best_bagging_model.get_params()}')\n",
        "\n",
        "# AdaBoost\n",
        "adaboost_param_grid = {\n",
        "    'n_estimators': [20, 50, 100],\n",
        "    'base_estimator__max_depth': [None, 5, 10]\n",
        "}\n",
        "\n",
        "adaboost_base_estimator = DecisionTreeClassifier()  # Instantiate the base estimator here\n",
        "adaboost_model = AdaBoostClassifier(base_estimator=adaboost_base_estimator, n_estimators=50, random_state=42)\n",
        "\n",
        "adaboost_grid_search = GridSearchCV(adaboost_model, adaboost_param_grid, cv=3, scoring='accuracy')\n",
        "adaboost_grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_adaboost_model = adaboost_grid_search.best_estimator_\n",
        "\n",
        "# Evaluate on the validation set\n",
        "adaboost_valid_predictions = best_adaboost_model.predict(X_valid)\n",
        "adaboost_valid_accuracy = accuracy_score(y_valid, adaboost_valid_predictions)\n",
        "print(f'Best AdaBoost Model Accuracy on Validation Set: {adaboost_valid_accuracy}')\n",
        "\n",
        "# Evaluate on the test set\n",
        "adaboost_test_predictions = best_adaboost_model.predict(X_test)\n",
        "adaboost_test_accuracy = accuracy_score(y_test, adaboost_test_predictions)\n",
        "print(f'Best AdaBoost Model Accuracy on Test Set: {adaboost_test_accuracy}')\n",
        "# print(f'Best AdaBoost Model Hyperparameters: {best_adaboost_model.get_params()}')\n",
        "\n",
        "# Random Forest\n",
        "random_forest_param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_features': [None, 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "random_forest_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "random_forest_grid_search = GridSearchCV(random_forest_model, random_forest_param_grid, cv=3, scoring='accuracy')\n",
        "random_forest_grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_random_forest_model = random_forest_grid_search.best_estimator_\n",
        "\n",
        "# Evaluate on the validation set\n",
        "random_forest_valid_predictions = best_random_forest_model.predict(X_valid)\n",
        "random_forest_valid_accuracy = accuracy_score(y_valid, random_forest_valid_predictions)\n",
        "print(f'Best Random Forest Model Accuracy on Validation Set: {random_forest_valid_accuracy}')\n",
        "\n",
        "# Evaluate on the test set\n",
        "random_forest_test_predictions = best_random_forest_model.predict(X_test)\n",
        "random_forest_test_accuracy = accuracy_score(y_test, random_forest_test_predictions)\n",
        "print(f'Best Random Forest Model Accuracy on Test Set: {random_forest_test_accuracy}')\n",
        "# print(f'Best Random Forest Model Hyperparameters: {best_random_forest_model.get_params()}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Randomized Search:**"
      ],
      "metadata": {
        "id": "FglXQ344X-1y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QA_EeGKfY0AT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bagging\n",
        "bagging_param_grid = {\n",
        "    'n_estimators': [5, 10, 20],\n",
        "    'base_estimator__max_depth': [None, 5, 10]  # Specify within the base estimator\n",
        "}\n",
        "\n",
        "bagging_base_estimator = DecisionTreeClassifier()\n",
        "bagging_model = BaggingClassifier(base_estimator=bagging_base_estimator, n_estimators=10, random_state=42)\n",
        "\n",
        "bagging_grid_search = GridSearchCV(bagging_model, bagging_param_grid, cv=3, scoring='accuracy')\n",
        "bagging_grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_bagging_model = bagging_grid_search.best_estimator_\n",
        "\n",
        "# Evaluate on the validation set\n",
        "bagging_valid_predictions = best_bagging_model.predict(X_valid)\n",
        "bagging_valid_accuracy = accuracy_score(y_valid, bagging_valid_predictions)\n",
        "print(f'Best Bagging Model Accuracy on Validation Set: {bagging_valid_accuracy}')\n",
        "\n",
        "# Evaluate on the test set\n",
        "bagging_test_predictions = best_bagging_model.predict(X_test)\n",
        "bagging_test_accuracy = accuracy_score(y_test, bagging_test_predictions)\n",
        "print(f'Best Bagging Model Accuracy on Test Set: {bagging_test_accuracy}')\n",
        "# print(f'Best Bagging Model Hyperparameters: {best_bagging_model.get_params()}')\n",
        "\n",
        "# AdaBoost\n",
        "adaboost_param_grid = {\n",
        "    'n_estimators': [5, 10, 20],\n",
        "    'base_estimator__max_depth': [None, 5, 10]\n",
        "}\n",
        "\n",
        "adaboost_base_estimator = DecisionTreeClassifier()  # Instantiate the base estimator here\n",
        "adaboost_model = AdaBoostClassifier(base_estimator=adaboost_base_estimator, n_estimators=50, random_state=42)\n",
        "\n",
        "adaboost_grid_search = GridSearchCV(adaboost_model, adaboost_param_grid, cv=3, scoring='accuracy')\n",
        "adaboost_grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_adaboost_model = adaboost_grid_search.best_estimator_\n",
        "\n",
        "# Evaluate on the validation set\n",
        "adaboost_valid_predictions = best_adaboost_model.predict(X_valid)\n",
        "adaboost_valid_accuracy = accuracy_score(y_valid, adaboost_valid_predictions)\n",
        "print(f'Best AdaBoost Model Accuracy on Validation Set: {adaboost_valid_accuracy}')\n",
        "\n",
        "# Evaluate on the test set\n",
        "adaboost_test_predictions = best_adaboost_model.predict(X_test)\n",
        "adaboost_test_accuracy = accuracy_score(y_test, adaboost_test_predictions)\n",
        "print(f'Best AdaBoost Model Accuracy on Test Set: {adaboost_test_accuracy}')\n",
        "# print(f'Best AdaBoost Model Hyperparameters: {best_adaboost_model.get_params()}')\n",
        "\n",
        "# Random Forest\n",
        "random_forest_param_grid = {\n",
        "    'n_estimators': [5, 10, 20],\n",
        "    'max_features': [None, 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "random_forest_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "random_forest_grid_search = GridSearchCV(random_forest_model, random_forest_param_grid, cv=3, scoring='accuracy')\n",
        "random_forest_grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_random_forest_model = random_forest_grid_search.best_estimator_\n",
        "\n",
        "# Evaluate on the validation set\n",
        "random_forest_valid_predictions = best_random_forest_model.predict(X_valid)\n",
        "random_forest_valid_accuracy = accuracy_score(y_valid, random_forest_valid_predictions)\n",
        "print(f'Best Random Forest Model Accuracy on Validation Set: {random_forest_valid_accuracy}')\n",
        "\n",
        "# Evaluate on the test set\n",
        "random_forest_test_predictions = best_random_forest_model.predict(X_test)\n",
        "random_forest_test_accuracy = accuracy_score(y_test, random_forest_test_predictions)\n",
        "print(f'Best Random Forest Model Accuracy on Test Set: {random_forest_test_accuracy}')\n",
        "# print(f'Best Random Forest Model Hyperparameters: {best_random_forest_model.get_params()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVyqwc58Xa2w",
        "outputId": "5d141ce8-64df-4999-bd95-3f3d05d0c6c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Bagging Model Accuracy on Validation Set: 0.7458556597454788\n",
            "Best Bagging Model Accuracy on Test Set: 0.7489639583071707\n",
            "Best AdaBoost Model Accuracy on Validation Set: 0.7429253181513731\n",
            "Best AdaBoost Model Accuracy on Test Set: 0.7445686299133493\n",
            "Best Random Forest Model Accuracy on Validation Set: 0.7242967180174146\n",
            "Best Random Forest Model Accuracy on Test Set: 0.7241826782201013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Bayesian methods:**"
      ],
      "metadata": {
        "id": "_ffDA5KbYZ0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import BayesSearchCV\n",
        "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Bagging\n",
        "bagging_param_dist = {\n",
        "    'n_estimators': (5, 20),\n",
        "    'base_estimator__max_depth': (1, 10)\n",
        "}\n",
        "\n",
        "bagging_base_estimator = DecisionTreeClassifier()\n",
        "bagging_model = BaggingClassifier(base_estimator=bagging_base_estimator, n_estimators=10, random_state=42)\n",
        "\n",
        "bagging_bayes_search = BayesSearchCV(bagging_model, bagging_param_dist, n_iter=10, cv=3, scoring='accuracy', random_state=42)\n",
        "bagging_bayes_search.fit(X_train, y_train)\n",
        "\n",
        "best_bagging_model = bagging_bayes_search.best_estimator_\n",
        "\n",
        "# Evaluate on the validation set\n",
        "bagging_valid_predictions = best_bagging_model.predict(X_valid)\n",
        "bagging_valid_accuracy = accuracy_score(y_valid, bagging_valid_predictions)\n",
        "print(f'Best Bagging Model Accuracy on Validation Set: {bagging_valid_accuracy}')\n",
        "\n",
        "# Evaluate on the test set\n",
        "bagging_test_predictions = best_bagging_model.predict(X_test)\n",
        "bagging_test_accuracy = accuracy_score(y_test, bagging_test_predictions)\n",
        "print(f'Best Bagging Model Accuracy on Test Set: {bagging_test_accuracy}')\n",
        "\n",
        "# AdaBoost\n",
        "adaboost_param_dist = {\n",
        "    'n_estimators': (10, 30),\n",
        "    'base_estimator__max_depth': (1, 10)\n",
        "}\n",
        "\n",
        "adaboost_base_estimator = DecisionTreeClassifier()  # Instantiate the base estimator here\n",
        "adaboost_model = AdaBoostClassifier(base_estimator=adaboost_base_estimator, n_estimators=50, random_state=42)\n",
        "\n",
        "adaboost_bayes_search = BayesSearchCV(adaboost_model, adaboost_param_dist, n_iter=10, cv=3, scoring='accuracy', random_state=42)\n",
        "adaboost_bayes_search.fit(X_train, y_train)\n",
        "\n",
        "best_adaboost_model = adaboost_bayes_search.best_estimator_\n",
        "\n",
        "# Evaluate on the validation set\n",
        "adaboost_valid_predictions = best_adaboost_model.predict(X_valid)\n",
        "adaboost_valid_accuracy = accuracy_score(y_valid, adaboost_valid_predictions)\n",
        "print(f'Best AdaBoost Model Accuracy on Validation Set: {adaboost_valid_accuracy}')\n",
        "\n",
        "# Evaluate on the test set\n",
        "adaboost_test_predictions = best_adaboost_model.predict(X_test)\n",
        "adaboost_test_accuracy = accuracy_score(y_test, adaboost_test_predictions)\n",
        "print(f'Best AdaBoost Model Accuracy on Test Set: {adaboost_test_accuracy}')\n",
        "\n",
        "# Random Forest\n",
        "random_forest_param_dist = {\n",
        "    'n_estimators': (20, 50),\n",
        "    'max_features': (None, 'sqrt', 'log2')\n",
        "}\n",
        "\n",
        "random_forest_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "random_forest_bayes_search = BayesSearchCV(random_forest_model, random_forest_param_dist, n_iter=10, cv=3, scoring='accuracy', random_state=42)\n",
        "random_forest_bayes_search.fit(X_train, y_train)\n",
        "\n",
        "best_random_forest_model = random_forest_bayes_search.best_estimator_\n",
        "\n",
        "# Evaluate on the validation set\n",
        "random_forest_valid_predictions = best_random_forest_model.predict(X_valid)\n",
        "random_forest_valid_accuracy = accuracy_score(y_valid, random_forest_valid_predictions)\n",
        "print(f'Best Random Forest Model Accuracy on Validation Set: {random_forest_valid_accuracy}')\n",
        "\n",
        "# Evaluate on the test set\n",
        "random_forest_test_predictions = best_random_forest_model.predict(X_test)\n",
        "random_forest_test_accuracy = accuracy_score(y_test, random_forest_test_predictions)\n",
        "print(f'Best Random Forest Model Accuracy on Test Set: {random_forest_test_accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SfYwPATYKja",
        "outputId": "3cfb6b32-3eef-49ef-c6c8-3029e0ed4ff3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Bagging Model Accuracy on Validation Set: 0.7461486939048895\n",
            "Best Bagging Model Accuracy on Test Set: 0.7495500020930135\n",
            "Best AdaBoost Model Accuracy on Validation Set: 0.7431346282652378\n",
            "Best AdaBoost Model Accuracy on Test Set: 0.7450290928879401\n",
            "Best Random Forest Model Accuracy on Validation Set: 0.7328365706630945\n",
            "Best Random Forest Model Accuracy on Test Set: 0.7331407760894135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Final System:"
      ],
      "metadata": {
        "id": "KBj8Ai92Zbxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bagging\n",
        "best_bagging_model = BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=best_bagging_model.base_estimator.max_depth),\n",
        "                                       n_estimators=best_bagging_model.n_estimators,\n",
        "                                       random_state=42)\n",
        "best_bagging_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on the test set\n",
        "bagging_test_predictions = best_bagging_model.predict(X_test)\n",
        "bagging_test_accuracy = accuracy_score(y_test, bagging_test_predictions)\n",
        "print(f'Bagging Model Accuracy on Test Set: {bagging_test_accuracy}')\n",
        "\n",
        "# AdaBoost\n",
        "best_adaboost_model = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=best_adaboost_model.base_estimator.max_depth),\n",
        "                                         n_estimators=best_adaboost_model.n_estimators,\n",
        "                                         random_state=42)\n",
        "best_adaboost_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on the test set\n",
        "adaboost_test_predictions = best_adaboost_model.predict(X_test)\n",
        "adaboost_test_accuracy = accuracy_score(y_test, adaboost_test_predictions)\n",
        "print(f'AdaBoost Model Accuracy on Test Set: {adaboost_test_accuracy}')\n",
        "\n",
        "# Random Forest\n",
        "best_random_forest_model = RandomForestClassifier(n_estimators=best_random_forest_model.n_estimators,\n",
        "                                                 max_features=best_random_forest_model.max_features,\n",
        "                                                 random_state=42)\n",
        "best_random_forest_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on the test set\n",
        "random_forest_test_predictions = best_random_forest_model.predict(X_test)\n",
        "random_forest_test_accuracy = accuracy_score(y_test, random_forest_test_predictions)\n",
        "print(f'Random Forest Model Accuracy on Test Set: {random_forest_test_accuracy}')\n",
        "\n",
        "# Find and print the best accuracy\n",
        "best_accuracy_model = max([(bagging_test_accuracy, 'Bagging'), (adaboost_test_accuracy, 'AdaBoost'), (random_forest_test_accuracy, 'Random Forest')])\n",
        "\n",
        "print(f'\\nBest Accuracy Model: {best_accuracy_model[1]} with Accuracy: {best_accuracy_model[0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_dw76VvZfYd",
        "outputId": "388ae465-d21f-4693-c105-b37f23239d0b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Model Accuracy on Test Set: 0.7495500020930135\n",
            "AdaBoost Model Accuracy on Test Set: 0.7450290928879401\n",
            "Random Forest Model Accuracy on Test Set: 0.7331407760894135\n",
            "\n",
            "Best Accuracy Model: Bagging with Accuracy: 0.7495500020930135\n"
          ]
        }
      ]
    }
  ]
}